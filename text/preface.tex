\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}


With the advent of affordable portable electronics, especially mobile phones, world's digital space has been flooded by user generated content, specifically photos and videos. Together with cheaper storage options, we are facing so called explosion of multimedia. Bigger than ever collections pose significant challenges for users to find what they are searching for. Challenges arise not only in personal videos. Miniaturization enabled new types of collections such as medical surgery or police body camera recordings.

The growing amount of data requires new effective approaches to image and video retrieval, because traditional methods were not able to deal efficiently with such a high dimensionality of an image or a video. There are two backbones of recent progress. The first are cheaper, more powerful GPUs. The second is creation of large-scale datasets, such as ImageNet~\cite{imagenet_cvpr09} and TRECVid~\cite{2017trecvidawad}, that enabled us to experiment with more sophisticated, but also more computationally demanding, models. All that led to recent breakthroughs in machine learning, especially artificial neural networks. It gave birth to new applications in fields of computer vision, speed recognition, text translation and many others.

Nowadays in computer vision, commercial services such as Google Images need not to rely on human labeling either on web page or by an external worker. Latest neural networks can, on some datasets, even exceed human performance~\cite{he2015delving}, thus one could assume it is a solved problem. Yet there are not many, if any, not task specific tools the author is aware of, that provide user an interface to organize and search in their collections for whatever their need is. One could argue Google Photos and YouTube have all the user's content three clicks away, but try to find a tank in thousands of images or videos respectively from dashboard cameras in either one of those services.



\todo{Missing}

